# 3.8 HyperLogLog (HLL)

> “유니크한 항목이 많으면
> 해시값에서 더 긴 ‘0의 연속 구간’이 등장한다.”

HyperLogLog는  
“데이터 속에서 **고유한 값이 몇 개 있는지**(Unique Count)”를  
**아주 작은 메모리만으로** 빠르게 추정하는 알고리즘이다.

예:
- 하루 동안 방문한 **유니크 사용자 수**
- API를 호출한 **고유 IP 수**
- 특정 이벤트를 발생시킨 **고유 userId 수**

고유 개수를 정확히 세려면 HashSet 같은 데 모두 저장해야 하지만,  
데이터가 많아질수록 메모리가 기하급수적으로 필요하다.

HyperLogLog는 이런 문제를 해결하기 위해 만들어졌다.

---

# 1. HyperLogLog는 왜 필요한가?

HashSet 기반 정확한 카운팅 방식의 문제:

- 수백만 / 수억 개를 저장하면 메모리 수백 MB~수 GB 필요
- key 자체(문자열/UUID/IP)를 모두 저장해야 함
- 분산 시스템에서는 더 큰 부하가 발생함

하지만 대부분의 경우  
“정확한 값 100%”는 필요하지 않고  
“대략 몇 명인지 / 몇 개인지”만 알면 되는 경우가 많다.

HLL은 이런 요구에 완벽하게 맞는다.

- 정확도는 98~99% 수준으로 충분히 높고
- 메모리는 **대략 1~2 KB로 고정**

---

# 2. HyperLogLog의 핵심 아이디어

HyperLogLog는 **key를 저장하지 않는다.**

대신:

1. key를 해시(hash)한다  
2. 해시값에서 **특징적인 패턴**을 추출한다  
3. 그 패턴을 아주 작은 메모리에 기록한다  

이 패턴 중 가장 중요한 것이 바로:

> “해시값이 0이 얼마나 오래 이어지나”  
> (leading zeros)

해시값이 완전 랜덤이라고 가정하면,  
데이터가 많아질수록 **길게 0이 이어진 해시값**이 나올 확률이 커진다.

즉,
- 데이터가 적으면 → 짧은 패턴만 관찰됨  
- 데이터가 많으면 → 더 길고 희귀한 패턴이 등장함

이 패턴을 기록하는 것만으로  
전체 데이터가 얼마나 많은지 “추정”할 수 있다.

---


# 3. 왜 메모리를 적게 사용하나?

- key 자체를 저장하지 않는다  
- 해시에서 나온 짧은 숫자(패턴)만 저장  
- 저장되는 정보는 “각 구역에서 본 가장 큰 패턴 길이”뿐  
- 방의 개수도 고정(수천 개)

즉:

> “몇 개인지 알려면 전체를 저장할 필요 없다  
> 패턴만 보면 된다”

이 원리 때문에 엄청난 압축이 가능해진다.

---

# 4. 왜 오차가 생기는가?

HyperLogLog는 **확률적 구조**다.

오차 이유:
1. 해시 충돌 → 다른 key가 비슷한 패턴을 만들 수 있다  
2. “패턴의 최대값만” 저장하는 구조 → 정보가 단순화됨  

---

# 5. Redis HyperLogLog 사용 예시

Redis에서는 아래 명령으로 HLL을 즉시 사용할 수 있다.

### 값 추가
```
PFADD unique_users user123
```

### 추정 고유값 조회
```
PFCOUNT unique_users
```

### 여러 HLL 병합
```
PFMERGE total_hll region1_hll region2_hll
```

----

# 6. 실제 사용 사례

### 1) 사이트 방문자 수(Unique Users)
매일 새로 방문한 사람들 수를 매우 저렴한 메모리로 추정.

### 2) Unique IP 모니터링
API 공격 탐지  
(동시에 들어오는 IP 수가 급증하는지)

### 3) 광고 / 추천 시스템
특정 광고를 본 unique deviceId 수 세기

### 4) 로그 수집 파이프라인(Kafka/Flink)
특정 이벤트의 unique count 추정

### 5) SNS/커뮤니티
특정 해시태그에 참여한 unique user 수 계산
