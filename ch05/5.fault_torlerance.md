# 목차

- [목차](#목차)
- [5.5 키-값 저장소의 장애 허용성과 장애 식별](#55-키-값-저장소의-장애-허용성과-장애-식별)
  - [5.5.1 일시적 장애 관리](#551-일시적-장애-관리)
  - [5.5.2 영구적 장애 관리](#552-영구적-장애-관리)
  - [5.5.3 해시 링의 노드 구성과 장애 감지](#553-해시-링의-노드-구성과-장애-감지)

# 5.5 키-값 저장소의 장애 허용성과 장애 식별

분산 키-값 저장소는 일부 노드의 장애를 정상적인 상황으로 가정하고 설계된다.  
시스템은 장애 상황에서도 가용성과 일관성을 최대한 유지해야 하며,  
이를 위해 장애 유형에 따라 다른 복구 및 식별 전략을 사용한다.

---

## 5.5.1 일시적 장애 관리  
### Hinted Handoff

### 개념

일시적 장애는 네트워크 지연, 프로세스 재시작, 짧은 시간의 노드 다운 등  
비교적 짧은 시간 내에 복구 가능한 장애를 의미한다.

Hinted Handoff는 이러한 상황에서  
쓰기 요청을 실패로 처리하지 않고,  
다른 노드가 임시로 데이터를 대신 저장하는 기법이다.

---

### 동작 방식

- 특정 노드가 일시적으로 응답하지 않는 상태가 발생
- 해당 노드에 저장되어야 할 데이터를 다른 정상 노드에 저장
- 이때 원래 대상 노드를 식별하기 위한 힌트 정보(hint)를 함께 기록
- 장애 노드가 복구되면
  - 임시 저장된 데이터를 원래 노드로 전달
  - 전달 완료 후 힌트 데이터 삭제

---

### 장점

- 일시적인 장애 상황에서도 쓰기 가용성 유지
- 클라이언트 입장에서 실패율 감소
- 복구 이후 데이터 정합성 회복 가능

---

### 한계 및 주의사항

- 장애가 장기화될 경우 힌트 데이터가 누적될 수 있음
- 힌트를 보관하는 노드에 부하 집중 가능
- 영구적 장애에는 적합하지 않음
- 힌트 보관 기간 및 크기에 대한 정책 필요

---

## 5.5.2 영구적 장애 관리  
### Merkle Tree

### 개념

영구적 장애(permanent failure)는 다음과 같은 상황을 의미한다.

- 디스크 손상
- 노드 폐기 또는 장기적인 다운
- 데이터 일부 또는 전체 유실
- 장기간 네트워크 격리 후 노드 복귀

이 경우 문제는 단순히 노드가 내려간 것이 아니라,  
**복구 이후 노드가 가진 데이터가 다른 노드와 달라질 수 있다는 점**이다.

---

## 2. 왜 단순 복제만으로는 충분하지 않은가

분산 키-값 저장소에서는 보통 데이터가 여러 노드에 복제된다.

하지만 영구적 장애 이후에는 다음 문제가 발생할 수 있다.

- 어떤 데이터가 유실되었는지 알기 어려움
- 전체 데이터를 다른 노드와 전부 비교해야 할 수도 있음
- 데이터 크기가 클 경우 네트워크 비용이 매우 큼

즉,  
**“무엇이 다른지”를 빠르게 찾아내는 메커니즘이 필요**하다.

---

## 3. Merkle Tree의 핵심 아이디어

Merkle Tree는 **데이터 집합의 상태를 해시 트리로 요약**한다.

구조적 특징은 다음과 같다.

- 리프 노드: 개별 데이터 블록(또는 키 범위)의 해시
- 내부 노드: 자식 노드 해시를 결합한 해시
- 루트 노드: 전체 데이터 집합을 대표하는 해시 값

이 구조를 통해  
**전체 데이터를 단 하나의 해시 값으로 요약**할 수 있다.

---

## 4. 영구적 장애 이후 동기화 과정

영구적 장애 이후 노드가 다시 클러스터에 참여하면  
다음과 같은 과정이 수행된다.

### 1단계: 루트 해시 비교

- 각 레플리카 노드는 자신의 Merkle Tree 루트 해시를 교환
- 루트 해시가 같다면 → 데이터는 동일, 동기화 불필요
- 루트 해시가 다르다면 → 데이터 불일치 존재

---

### 2단계: 하위 트리 비교

- 루트가 다를 경우, 자식 노드의 해시 비교
- 해시가 다른 쪽으로만 내려가며 비교 범위를 점점 좁힘
- 결국 **불일치가 발생한 최소 데이터 범위**를 찾아냄

---

### 3단계: 필요한 데이터만 복구

- 불일치가 확인된 키 범위의 데이터만
  - 정상 노드 → 장애에서 복구된 노드로 전송
- 전체 데이터 복사가 아닌 **부분 복구** 수행

이 과정이 끝나면,  
장애에서 복구된 노드는 클러스터와 동일한 데이터 상태로 수렴한다.

---

## 5.5.3 해시 링의 노드 구성과 장애 감지  
### Gossip Protocol이 분산 시스템에서 장애를 감지하고 확산을 제어하는 방식

Gossip Protocol은 분산 시스템에서  
**노드 상태 정보를 전파하고 장애를 감지하기 위한 분산 통신 메커니즘**이다.

Merkle Tree가 “장애 이후 데이터 정합성을 복구”하는 역할이라면,  
Gossip Protocol은 **“장애를 빠르게 인지하고 클러스터 전체에 공유”**하는 역할을 담당한다.

즉, 목적은  
**중앙 통제 없이 장애 정보를 퍼뜨리고, 시스템이 스스로 수렴하게 만드는 것**이다.

---

### 1. Gossip Protocol이 필요한 이유

대규모 분산 시스템에서는 다음과 같은 제약이 존재한다.

- 중앙 관리 노드(SPOF)를 두기 어려움
- 노드 수가 많아질수록 직접적인 상태 체크 비용 증가
- 네트워크 지연, 일시적 분리 상황 발생 가능

이러한 환경에서는  
“모든 노드의 상태를 항상 정확히 알고 있는 중앙 시스템”보다  
**확률적이지만 확장 가능한 방식**이 더 적합하다.

---

### 2. Gossip Protocol의 기본 아이디어

Gossip Protocol은 사람들 사이의 소문(gossip) 전파와 유사하게 동작한다.

- 각 노드는 클러스터 전체 상태를 완벽히 알 필요가 없음
- 대신, **일부 노드의 상태만 알고** 이를 서로 교환
- 이 정보는 반복적인 교환을 통해 클러스터 전체로 확산
- 충분한 시간이 지나면 모든 노드가 유사한 상태 인식을 가지게 됨

정확성을 즉시 보장하기보다는  
**최종 수렴(Eventual Convergence)**을 목표로 한다.

---

### 3. 노드 상태 전파 방식

### 주기적 랜덤 통신

- 각 노드는 일정 주기로 임의의 다른 노드를 선택
- 자신의 상태 정보와 알고 있는 타 노드 상태 정보를 전송
- 상대 노드 역시 자신의 정보를 응답

이 과정은 다음 특징을 가진다.

- 통신 대상이 고정되지 않음
- 네트워크 부담이 노드 수에 비례해 증가하지 않음
- 일부 노드 장애가 전체 전파를 막지 못함

---

### 상태 정보의 구성

노드가 공유하는 정보에는 보통 다음이 포함된다.

- 노드 ID
- 상태 값 (정상, 의심, 장애)
- 마지막 응답 시각(타임스탬프)
- 버전 정보 또는 세대 번호

노드는 이를 바탕으로  
상대 노드가 최신 상태인지 판단한다.

---

### 4. 장애 감지 과정

Gossip Protocol은 일반적으로  
**의심(suspect) → 확정(faulty)**의 두 단계 장애 감지 모델을 사용한다.

**1단계: 의심 상태(Suspect)**

- 특정 노드로부터 일정 시간 동안 응답이 없음
- 즉시 장애로 판단하지 않고 의심 상태로 표시
- 이 정보는 Gossip을 통해 다른 노드에게 전파됨

---

**2단계: 장애 확정(Faulty)**

- 다수 노드에서 동일한 노드를 의심 상태로 판단
- 일정 횟수 이상의 실패 또는 타임아웃 발생
- 해당 노드를 장애 노드로 확정

이 과정을 거침으로써  
일시적인 네트워크 지연으로 인한 오탐(false positive)을 줄인다.

---

### 5. 최종 수렴(Eventual Convergence)

Gossip Protocol의 핵심 철학은  
**모든 노드가 즉시 정확해야 할 필요는 없다는 것**이다.

- 노드별로 상태 인식은 다를 수 있음
- 그러나 시간이 지나면 정보가 전파되며
- 모든 노드는 동일하거나 유사한 클러스터 상태로 수렴

이 특성은 다음과 같은 장점을 가진다.

- 대규모 시스템에서도 안정적인 동작
- 일부 메시지 유실에도 시스템 전체 영향 최소화
- 네트워크 파티션 이후에도 자연스러운 복구

---

### 6. 영구적 장애 및 노드 제거 처리

노드가 영구적으로 장애 상태로 판단되면:

- 해당 노드는 클러스터 멤버십에서 제거
- 해시 링 또는 파티션 할당 정보에서 제외
- 해당 노드가 담당하던 데이터 범위를 다른 노드가 인계

이 과정에서도  
중앙 관리자는 필요하지 않으며,  
Gossip을 통해 변경 사항이 공유된다.

---

### 7. Gossip Protocol의 한계

Gossip Protocol은 강력하지만, 다음과 같은 한계를 가진다.

- 장애 인지까지 일정 시간 지연 발생
- 상태 정보가 항상 즉시 정확하지 않음
- 네트워크 분리 상황에서 일시적인 상태 불일치 발생 가능

그러나 설계상 이는 의도된 trade-off이며,  
확장성과 가용성을 위해 받아들여지는 선택이다.

---

### 8. Merkle Tree와의 역할 비교

- Gossip Protocol
  - 노드 상태와 장애 정보를 전파
  - “누가 살아 있고, 누가 죽었는지”를 공유

- Merkle Tree
  - 데이터 불일치 탐지 및 복구
  - “데이터가 무엇이 다른지”를 식별

두 메커니즘은 함께 사용되어  
분산 시스템의 **장애 감지 + 데이터 정합성 회복**을 완성한다.