# **2.6 내구성(Durability)**

내구성(Durability)은 **데이터가 성공적으로 저장되었다면, 시스템 장애가 나더라도 절대 사라지지 않는 특성**을 의미한다.

즉 “성공했다고 응답한 데이터는 영원히 남아 있어야 한다”는 보장이다.

---

## **1. 내구성이 중요한 이유**

- 시스템은 장애가 언제 발생할지 알 수 없음  
- 디스크 고장, 프로세스 크래시, 전원 장애 등이 발생해도  
  *이미 저장했다고 응답한 데이터는 절대 유실되면 안 됨*

예:  
- 금융 거래 기록  
- 주문/결제 기록  
- 예약 성공 여부  
- Kafka 로그(메시지 스트림)

---

# **2. 내구성을 보장하는 방식**

## **1) Write-Ahead Logging (WAL)**
DB·Kafka·스토리지 대부분이 사용하는 방식.  
쓰기 요청이 들어오면 **메모리에 먼저 반영하는 것이 아니라, 로그 파일에 변경을 기록한 뒤 Commit**을 수행한다.

- PostgreSQL WAL  
- MySQL Redo Log  
- Kafka Commit Log

**장점:** 강한 내구성  
**단점:** 디스크 I/O가 증가하여 지연 시간이 늘어남

---

## **2) 동기 디스크 쓰기 (fsync)**
데이터가 디스크에 안전하게 기록될 때까지 응답을 지연시키는 방식.

- "디스크에 실제로 기록됐다"까지 기다리므로 매우 안전
- 하지만 가장 느림

---

## **3) 복제(Replication)를 통한 내구성 강화**
- 여러 노드에 데이터를 복제해 “노드가 죽어도 데이터가 남아있게” 한다.
- 특히 **동기(Sync) 복제**는 강한 내구성을 만들어줌.

예: Kafka acks=all + min.insync.replicas ≥ 2

---

# **3. 내구성과 Trade-off**

내구성은 항상 **지연 시간(Latency)**과 밀접한 트레이드오프 관계다.

## **3-1. 내구성 ↑ → 지연 시간 ↑**

- 디스크 플러시 필요  
- 여러 노드 동기화 필요  
- 네트워크 Round-trip 증가

그래서 금융·예약처럼 **정확성 > 속도**인 시스템에서 선호된다.

---

## **3-2. 지연 시간 ↓ → 내구성 ↓**

- 메모리에 먼저 기록하고 나중에 디스크에 flush → 크래시 시 데이터 유실 가능
- 비동기 복제 → 모든 레플리카에 반영되지 않은 상태로 응답 가능

이 방식은 **로그·분석·메트릭·SNS**처럼 “일부 유실되어도 괜찮은” 시스템에서 선택된다.

---

# **4. 내구성 수준별 비교**

| 내구성 수준 | 설명 | 장점 | 단점 | 사용 사례 |
|-------------|------|------|------|-----------|
| **강한 내구성** | 저장이 디스크/복제 완료될 때까지 응답하지 않음 | 데이터 절대 유실 없음 | 지연 시간 증가 | 결제, 예약, 거래 |
| **중간 내구성** | 메모리→WAL 기록 후 응답, 백그라운드 flush | 성능 향상 | 순간 장애 시 일부 유실 가능 | 대규모 API 서버 |
| **약한 내구성** | 메모리에서 바로 응답, 나중에 비동기 쓰기 | 매우 빠름 | 유실 가능성 큼 | 로그·메트릭 시스템 |

---

# **5. Kafka를 예로 본 내구성 설정**

| 설정 | 설명 | 내구성 수준 |
|------|------|-------------|
| `acks=0` | 리더가 받았는지 확인하지 않음 | 가장 약함 |
| `acks=1` | 리더만 저장하면 OK | 중간 내구성 |
| `acks=all` + `min.insync.replicas ≥ 2` | ISR 모두 저장해야 OK | 매우 강함 |
| `unclean.leader.election=false` | 유실을 막기 위해 ISR만 리더 승격 | 강함 |

