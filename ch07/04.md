# Kafka Streams 설계 (Kafka Streams Architecture & Design)

Kafka Streams는 **Kafka 토픽을 입력으로 받아 실시간으로 변환/조인/집계하여 결과를 다시 Kafka 토픽으로 내보내는 스트림 처리 라이브러리**다.  
별도의 클러스터(예: Spark/Flink) 없이 **애플리케이션 프로세스 자체가 스트림 처리 엔진**으로 동작한다.

---

## 1. Kafka Streams를 쓰는 이유 (언제 적합한가)

### 1.1 적합한 상황
- 실시간 이벤트를 **필터/변환/집계/조인** 해서 다른 토픽으로 흘려야 할 때
- 운영 복잡도를 낮추고 싶을 때(별도 스트림 클러스터 없이 앱만 배포)
- **Kafka 토픽 간 파이프라인**(ETL, enrichment, routing)을 안정적으로 만들고 싶을 때
- Exactly-once(옵션)를 활용해 **중복/정합성 문제를 줄이고 싶을 때**

### 1.2 덜 적합한 상황
- 초대규모 분석/복잡한 배치(머신러닝 학습 등)처럼 **클러스터 컴퓨팅이 필요한 경우**
- Kafka 외부 소스/싱크가 매우 복잡한데 Connect/외부 엔진이 더 자연스러운 경우
- 상태(state) 규모가 너무 커서 앱 레벨 저장/복구 부담이 큰 경우(설계로 해결 가능하지만 비용↑)

---

## 2. 핵심 개념 정리 (Streams DSL 관점)

### 2.1 KStream vs KTable
- **KStream**
  - “이벤트 스트림”
  - 같은 키로 여러 이벤트가 계속 들어온다.
  - 예: 주문 이벤트 흐름(order_created, order_paid, ...)

- **KTable**
  - “최신 상태(Changelog)”
  - 키당 최신 값이 유지되는 테이블 개념(업데이트/업서트)
  - 예: 사용자 프로필(키=userId, 값=최신 프로필)

**실무 감각**
- 이벤트 중심 처리 → KStream
- “최신 상태 참조/조인/집계 결과 유지” → KTable

### 2.2 Topology
Kafka Streams 애플리케이션 내부에서 정의되는 **처리 그래프**.
- Source(입력 토픽) → Processor(변환/조인/집계) → Sink(출력 토픽)

### 2.3 Task / Thread / Partition
- Kafka Streams는 **토픽 파티션을 기준으로 Task를 나누고 병렬 처리**한다.
- 병렬성은 기본적으로 **입력 토픽 파티션 수**에 의해 결정된다.
- 인스턴스(프로세스)를 늘리면 Task가 재배치된다(=리밸런싱).

---

## 3. 상태 기반 처리(Stateful Processing)

Kafka Streams의 강점은 **stateful 연산(집계/윈도우/조인)** 을 앱에서 안전하게 수행하는 것이다.

### 3.1 State Store
집계/조인에 필요한 상태를 로컬에 저장하는 저장소.
- 기본적으로 RocksDB 기반(로컬 디스크) 사용이 일반적
- 로컬이지만, 장애 복구를 위해 **Changelog Topic**으로 상태 변경 로그를 Kafka에 기록한다.

### 3.2 Changelog Topic (복구의 핵심)
- State Store의 변경 사항을 Kafka 토픽에 기록
- 앱 장애/재시작 시:
  1) State Store 복구
  2) Changelog를 재생(replay)하여 상태를 재구성

> 즉, “상태를 로컬에 두되, Kafka에 로그로 백업해서 복구 가능하게” 만드는 구조다.

---

## 4. 시간 개념: Event Time / Processing Time / Ingestion Time

스트림 처리에서 “시간”은 품질을 좌우한다.

- **Processing Time**
  - 앱이 처리한 시각 기준
  - 단순하지만 지연/재처리에서 왜곡 가능

- **Event Time**
  - 이벤트 자체에 담긴 발생 시간(timestamp) 기준
  - 지연 도착(out-of-order) 처리에 강함
  - 윈도우 집계에 일반적으로 권장

- **Ingestion Time**
  - Kafka에 적재된 시각 기준

실무 권장:
- 대부분의 윈도우/집계는 **Event Time** 기반으로 설계하고,
- 지연 도착 허용 범위(=grace)를 명확히 둔다.

---

## 5. 윈도우(Window) 설계 (집계의 핵심)

Kafka Streams는 윈도우 집계를 다양한 형태로 제공한다.

### 5.1 Tumbling Window
- 겹치지 않는 고정 구간
- 예: 1분 단위 주문 수 집계

### 5.2 Hopping Window
- 겹치는 고정 구간(슬라이딩 느낌)
- 예: 최근 5분 주문 수를 1분마다 갱신

### 5.3 Session Window
- “활동” 기준으로 동적 구간
- 예: 사용자가 30초 이상 이벤트가 없으면 세션 종료

### 5.4 Grace Period (지연 도착 허용)
- 늦게 도착한 이벤트를 어느 정도까지 반영할지 결정
- 너무 짧으면 데이터 누락, 너무 길면 상태/메모리 비용 증가

---

## 6. 조인(Join) 설계

### 6.1 KStream-KTable Join (Enrichment에 자주 사용)
- 이벤트 스트림에 “최신 상태 테이블”을 붙이는 형태
- 예: 주문 이벤트(KStream)에 사용자 프로필(KTable) 조인

장점:
- 실무에서 가장 흔하고 안정적
- 상태 테이블이 최신이면 enrichment가 단순해짐

### 6.2 KStream-KStream Join (시간 기반 조인)
- 두 이벤트 스트림을 **시간 창(window)** 내에서 매칭
- 예: 결제요청 이벤트와 결제승인 이벤트를 10분 윈도우로 매칭

주의:
- 윈도우/지연 도착/메모리 사용량 설계가 중요

### 6.3 GlobalKTable
- 전체 파티션을 모든 인스턴스에 복제해 참조하는 테이블
- 작은 참조 데이터(코드 테이블 등)에 적합
- 데이터가 크면 메모리/복제 비용이 큼

---

## 7. Exactly-once(정확히 한 번)와 정합성

### 7.1 보장 수준
Kafka Streams는 설정에 따라:
- At-least-once
- Exactly-once(EOS, 정확히 한 번에 가까운 처리)

을 제공한다.

### 7.2 EOS의 의미(현실적 관점)
Kafka Streams의 EOS는 “Kafka 입력 → 처리 → Kafka 출력 + 상태 저장” 경로에서 강하다.

하지만 결과를 외부 DB에 쓰는 순간부터는:
- DB write 멱등성
- 트랜잭션 경계/Outbox 패턴
이 별도로 필요하다.

---

## 8. 실패 처리와 오류 전략

Kafka Streams는 기본적으로 “레코드 처리 중 예외가 터지면” 애플리케이션이 중단될 수 있다.  
따라서 **Deserialization/처리 예외 대응**을 설계해야 한다.

### 8.1 역직렬화(Serde) 오류
- 잘못된 포맷/스키마 불일치로 발생
- 대응:
  - 실패 레코드를 DLQ 토픽으로 보내고 skip
  - 스키마 호환 정책 강화

### 8.2 처리 로직 예외
- 특정 데이터 케이스에서 예외 발생(Null, 범위 등)
- 대응:
  - 예외를 잡아서 DLQ/에러 토픽으로 라우팅
  - 재시도는 “같은 레코드를 다시 처리”하는 형태이므로 poison message가 되기 쉬움 → 격리 전략이 중요

---

## 9. 성능/운영 설계 포인트

### 9.1 병렬성
- 인스턴스를 늘려도 **파티션 수 이상으로 병렬 처리 불가**
- 높은 TPS가 필요하면:
  - 입력 토픽 파티션 확대
  - 키 분산(핫키 방지)
  - state store/rocksdb 튜닝

### 9.2 리밸런싱 비용
- 인스턴스 증감/재시작 시 Task가 이동하고 state가 복구된다.
- state가 크면 복구 시간이 길어짐
- 대응:
  - 안정적인 배포 전략(rolling)
  - state 용량 관리(윈도우/TTL)
  - standby replica(개념적으로) 활용 고려(운영 전략)