# Kafka 기반 발행/구독(Pub/Sub) 시스템 설계

## 1. Kafka에서 Pub/Sub가 어떻게 구현되는가

Kafka는 “큐”라기보다 **분산 로그(Distributed Commit Log)** 에 가깝다.  
Producer는 토픽에 레코드를 **append(추가 기록)** 하고, Consumer는 자신의 **오프셋(offset)** 을 기준으로 로그를 읽는다.

핵심 포인트는 다음이다.

- 메시지는 토픽 파티션에 순차적으로 쌓인다.
- 소비자는 “삭제된 큐”를 읽는 게 아니라, “로그를 어디까지 읽었는지(오프셋)”를 관리한다.
- 동일 토픽이라도 **Consumer Group** 구성에 따라 “작업 분산(Queue-like)” 또는 “Fan-out(Pub/Sub)”이 된다.

---

## 2. 기본 구성요소와 설계 단위

### 2.1 Topic
- 메시지 스트림의 논리 단위
- 설계 시 결정해야 하는 것
  - 토픽 이름/소유권
  - 파티션 수
  - 복제 계수(replication factor)
  - 보존 정책(retention)

### 2.2 Partition
- Kafka의 **병렬 처리 단위**이자 **순서 보장 단위**
- 파티션 내부에서는 오프셋이 증가하며 순서가 유지된다.
- 전역 순서가 아니라 **“파티션 내 순서”** 만 보장된다.

### 2.3 Producer
- 레코드를 토픽에 기록
- 핵심 설계 요소
  - key 선택(=파티션 결정)
  - 전송 보장(acks, retries, idempotence)
  - 배치/압축(성능 최적화)

### 2.4 Consumer + Consumer Group
- 같은 group.id를 공유하는 소비자들은 파티션을 **분할(assign)** 받아 처리한다.
- 다른 group.id는 서로 독립적으로 같은 메시지를 각각 읽는다(=fan-out).

---

## 3. 토픽 설계(가장 중요)

### 3.1 토픽 분리 기준
권장 우선순위:
1) **도메인/Bounded Context**
2) 이벤트 타입(업무 의미)
3) 소유 팀(운영 책임)

예:
- `order.events`
- `payment.events`
- `user.profile.events`

가능하면 “범용 토픽 하나에 eventType만 넣는 방식”은 피한다.  
(스키마/권한/보존/부하/운영이 한데 엉켜 어려워짐)

### 3.2 파티션 수 산정 기준
파티션은 늘리기 쉽지만(대개 가능), 줄이기 어렵다.  
초기 산정은 다음을 고려한다.

- 목표 처리량(TPS)
- 소비자 병렬성(인스턴스 수)
- 키 기반 순서 요구(파티션 수가 늘면 키 분산이 더 잘 됨)
- 리밸런싱 비용(파티션이 많을수록 조정 비용 증가)

실무 팁:
- “소비자 최대 병렬 처리 수”는 파티션 수를 넘을 수 없다.
- 파티션이 너무 많으면 컨트롤 플레인 부하(메타데이터, 리밸런싱)가 증가한다.

### 3.3 Key 설계 = 순서/부하 설계
Kafka에서 key는 보통 **파티션 결정**에 사용된다(기본 파티셔너 기준).

- 주문 단위 순서 필요 → key = `orderId`
- 유저 단위 순서 필요 → key = `userId`

안티패턴:
- key가 없거나 랜덤 UUID → 순서 요구가 깨지고, 재처리 시 의미가 약해짐
- 소수 값 key(예: country) → 핫 파티션 발생

---

## 4. 전달 보장(Delivery Semantics) 설계

Kafka 자체는 “전달 보장”을 단일 기능으로 제공하지 않고,  
**Producer 설정 + Consumer 오프셋 커밋 + 처리 멱등성** 조합으로 달성한다.

### 4.1 At-most-once
- 소비자가 처리 전에 오프셋을 먼저 커밋
- 빠르지만 유실 가능

### 4.2 At-least-once (가장 일반적)
- “처리 성공 후 오프셋 커밋”
- 유실 최소, 중복 가능 → 소비자 멱등 처리 필수

### 4.3 Exactly-once (EOS)
Kafka의 EOS는 “Kafka 내부(토픽 간)”에서 강해진다.  
즉, “소비 후 다른 Kafka 토픽에 생산” 같은 파이프라인에서 의미가 크다.

- Producer idempotence + transactions
- Consumer의 read-process-write를 트랜잭션 경계로 묶음

주의:
- 외부 DB write/외부 API 호출까지 “완전한 exactly-once”를 만드는 건 추가 설계가 필요하다.
- 현실적인 해법은 “at-least-once + 멱등성 + outbox/inbox” 조합인 경우가 많다.

---

## 5. Producer 설계(신뢰성/성능)

### 5.1 핵심 설정(개념 중심)
- `acks`
  - `all`: 리더 + ISR 복제 확인 후 응답 (내구성↑, 지연↑)
- `enable.idempotence=true`
  - 재시도 상황에서 중복 전송을 줄여줌(중복 방지 핵심)
- `retries`, `delivery.timeout.ms`
  - 일시적 장애에서 전송 성공률을 높임

### 5.2 배치/압축 최적화
- 배치가 커질수록 처리량↑ / 지연↑ 가능
- 압축은 네트워크/디스크 절약 vs CPU 비용

대표 개념:
- `linger.ms`(배치를 모으는 시간)
- `batch.size`(배치 크기)
- `compression.type`(압축)

---

## 6. Consumer 설계(리밸런싱/커밋/역압)

### 6.1 오프셋 커밋 전략
- 자동 커밋(auto-commit)은 편하지만, 장애/중복/유실 제어가 어렵다.
- 보통은 “처리 성공 후 수동 커밋”을 선호한다.

### 6.2 리밸런싱(Rebalancing)
Consumer group의 구성원이 변하거나(Scale out/in),
파티션 수가 변하면 파티션 재할당이 발생한다.

리밸런싱이 잦아지면:
- 처리 중단(일시적) 또는 지연 증가
- 중복 처리 가능성 증가(커밋 타이밍에 따라)

원인 예시:
- 처리 시간이 길어 폴링 간격이 벌어짐
- 네트워크 지연/GC pause
- 컨테이너 스케일링/재시작

대응 방향:
- 처리 시간에 맞게 세션/폴링 관련 설정 조정
- 배치 처리, I/O 분리(워커 풀)
- 과도한 컨슈머 증설 지양(파티션 대비)

### 6.3 Backpressure(역압)와 Lag
Kafka에서 적체는 보통 **Lag**로 나타난다.

- 생산 속도 > 소비 속도 → Lag 증가
- Lag이 증가하면 end-to-end 지연이 커짐

대응:
- 소비자 병렬성 증가(파티션 범위 내)
- 처리 로직 최적화/배치화
- 파티션 확장(필요 시)
- 메시지 크기/압축/네트워크 병목 점검

---

## 7. 실패 처리(재시도, DLQ, 재처리)

### 7.1 재시도(Consumer Side)
처리 실패 시 즉시 재시도는 폭발을 유발할 수 있다.

권장:
- 지수 백오프 + 지터
- 최대 재시도 횟수 제한
- 실패 메시지 격리(DLQ)

### 7.2 DLQ(Dead Letter Topic)
처리 실패 메시지를 별도 토픽으로 보내고 본 흐름을 유지한다.

DLQ 메시지에 포함 권장:
- 원본 토픽/파티션/오프셋
- 실패 원인(에러 코드/스택)
- 재시도 횟수
- eventId/traceId

### 7.3 재처리(Replay) 전략
Kafka는 로그이므로 재처리가 자연스럽다.

대표 전략:
- consumer group을 새로 만들어 처음부터 재처리
- 특정 오프셋 시점으로 되돌려 재처리(운영 도구 필요)
- DLQ 토픽을 별도 리플레이 파이프라인으로 복구

---

## 8. 데이터 정합성 강화 패턴

### 8.1 Outbox 패턴(발행 정합성)
DB 변경과 이벤트 발행을 “느슨하지만 안전하게” 맞추는 전략.

- 트랜잭션 내 Outbox 테이블에 이벤트 저장
- 별도 릴레이가 Kafka로 발행
- 성공 시 Outbox 상태 업데이트

효과:
- “DB는 업데이트됐는데 이벤트 발행이 실패” 같은 불일치 최소화

### 8.2 Inbox 패턴(소비 멱등성)
소비자가 이벤트 처리 여부를 저장해 중복을 방지한다.

- eventId를 unique로 저장
- 이미 처리된 eventId면 skip

---

## 9. 운영/관측(Observability)

### 9.1 필수 지표
- Producer: 전송 실패율, 재시도율, 요청 지연
- Broker: ISR 상태, under-replicated partition, request latency
- Consumer: lag, 처리율, 실패율, 리밸런싱 빈도
- End-to-end latency: producedAt ~ processedAt

### 9.2 로그/추적
메시지 메타에 다음을 포함하면 운영 난이도가 크게 내려간다.
- `eventId`
- `traceId` / `correlationId`
- `producer`, `schemaVersion`, `occurredAt`

---

## 10. 보안(접근 제어)

- SASL/SSL/OAuth 등 인증 체계 선택
- 토픽 단위 ACL/RBAC
- 생산자/소비자 계정 분리
- 민감 이벤트 토픽 분리 및 필드 마스킹/암호화

---

## 11. Kafka 기반 Pub/Sub 안티패턴

- “토픽 하나로 모든 이벤트 처리” (스키마/권한/보존/부하가 꼬임)
- key 설계 실패로 핫 파티션 발생
- 무한 재시도로 파이프라인 정지(DLQ 없음)
- auto-commit 사용으로 유실/중복 통제 불가
- 소비 로직이 멱등하지 않아 중복 처리로 데이터 오염
- 리밸런싱 원인을 고려하지 않고 컨슈머만 무작정 증설